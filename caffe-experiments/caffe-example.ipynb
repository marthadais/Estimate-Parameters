{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNN to Validate the Architecture Designed\n",
    "\n",
    "Before starting, the following instructions require Caffe deep learning framework installed, and a brief knowledge about it. Instructions for installing Caffe are available at <http://caffe.berkeleyvision.org/installation.html>, and the basic tutorials at <http://caffe.berkeleyvision.org/gathered/examples/mnist.html>. In addition, this example requires the CMU Face Images dataset, which is available at <https://archive.ics.uci.edu/ml/datasets/CMU+Face+Images>.\n",
    "\n",
    "Files for training the CNN architecture are available in folder 'caffe-experiments', that contains the example files. \n",
    "\n",
    "### Executing CNN training for CMU Face Images dataset\n",
    "\n",
    "Our example topology is composed of one convolutional layer with ReLU activation function, followed by a sub-sampling max-pooling layer, a fully-connected layer, and a soft-max classifier. This fully-connected layer has $20$ units, which is the number of labels to classify the person in a given image. However, this dataset can be also classified according to other labels as pose (left, right, up, straight), expression (happy, sad, angry, neutral), and eyes (wearing sunglasses or not). It is worth to mention that we are working with images, while the Caffe tutorial work with LMDB databases.\n",
    "\n",
    "The files used in this example are example_solver.prototxt and example_topology.prototxt. The solver file uses the SGD to train the CNN with a learning rate equals to 0.001, momentum 0.9, and regularization term 0.004 (see <http://caffe.berkeleyvision.org/tutorial/solver.html> for more information). The topology file has the CNN architecture information, in which the mask convolutional size is 4x4 with 10 units, and the max-pooling has size 3x3 with stride equals to 2x2. Having all files prepared, we can perform the CNN training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "./caffe-master/build/tools/caffe train --solver=./example_solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I0524 09:37:36.962682  4162 caffe.cpp:218] Using GPUs 0\n",
    "I0524 09:37:36.970319  4162 caffe.cpp:223] GPU 0: GeForce GT 540M\n",
    "I0524 09:37:37.148581  4162 solver.cpp:44] Initializing solver from parameters: \n",
    "test_iter: 100\n",
    "test_interval: 500\n",
    "base_lr: 0.001\n",
    "display: 100\n",
    "max_iter: 10000\n",
    "lr_policy: \"fixed\"\n",
    "momentum: 0.9\n",
    "weight_decay: 0.004\n",
    "snapshot: 1000\n",
    "snapshot_prefix: \"models/cmu_example_train\"\n",
    "solver_mode: GPU\n",
    "device_id: 0\n",
    "net: \"example_topology.prototxt\"\n",
    "train_state {\n",
    "  level: 0\n",
    "  stage: \"\"\n",
    "}\n",
    "type: \"SGD\"\n",
    "I0524 09:37:37.148751  4162 solver.cpp:87] Creating training net from net file: example_topology.prototxt\n",
    "I0524 09:37:37.148989  4162 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer cmu\n",
    "I0524 09:37:37.149005  4162 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1\n",
    "I0524 09:37:37.149099  4162 net.cpp:53] Initializing net from parameters: \n",
    "name: \"simpleNet\"\n",
    "state {\n",
    "  phase: TRAIN\n",
    "  level: 0\n",
    "  stage: \"\"\n",
    "}\n",
    "layer {\n",
    "  name: \"cmu\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"cmu-list-train.txt\"\n",
    "    batch_size: 100\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    pad_h: 2\n",
    "    pad_w: 2\n",
    "    kernel_h: 4\n",
    "    kernel_w: 4\n",
    "    stride_h: 1\n",
    "    stride_w: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"conv1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"pool1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 3\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool1\"\n",
    "  top: \"ip1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 20\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"ip1\"\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "}\n",
    "I0524 09:37:37.149154  4162 layer_factory.hpp:77] Creating layer cmu\n",
    "I0524 09:37:37.149195  4162 net.cpp:86] Creating Layer cmu\n",
    "I0524 09:37:37.149207  4162 net.cpp:382] cmu -> data\n",
    "I0524 09:37:37.149236  4162 net.cpp:382] cmu -> label\n",
    "I0524 09:37:37.149255  4162 image_data_layer.cpp:38] Opening file cmu-list-train.txt\n",
    "I0524 09:37:37.149499  4162 image_data_layer.cpp:63] A total of 440 images.\n",
    "I0524 09:37:37.150198  4162 image_data_layer.cpp:90] output data size: 100,3,30,32\n",
    "I0524 09:37:37.154351  4162 net.cpp:124] Setting up cmu\n",
    "I0524 09:37:37.154384  4162 net.cpp:131] Top shape: 100 3 30 32 (288000)\n",
    "I0524 09:37:37.154392  4162 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:37:37.154398  4162 net.cpp:139] Memory required for data: 1152400\n",
    "I0524 09:37:37.154408  4162 layer_factory.hpp:77] Creating layer conv1\n",
    "I0524 09:37:37.154434  4162 net.cpp:86] Creating Layer conv1\n",
    "I0524 09:37:37.154444  4162 net.cpp:408] conv1 <- data\n",
    "I0524 09:37:37.154464  4162 net.cpp:382] conv1 -> conv1\n",
    "I0524 09:37:37.155252  4162 net.cpp:124] Setting up conv1\n",
    "I0524 09:37:37.155270  4162 net.cpp:131] Top shape: 100 10 31 33 (1023000)\n",
    "I0524 09:37:37.155277  4162 net.cpp:139] Memory required for data: 5244400\n",
    "I0524 09:37:37.155302  4162 layer_factory.hpp:77] Creating layer relu1\n",
    "I0524 09:37:37.155313  4162 net.cpp:86] Creating Layer relu1\n",
    "I0524 09:37:37.155319  4162 net.cpp:408] relu1 <- conv1\n",
    "I0524 09:37:37.155328  4162 net.cpp:369] relu1 -> conv1 (in-place)\n",
    "I0524 09:37:37.155339  4162 net.cpp:124] Setting up relu1\n",
    "I0524 09:37:37.155346  4162 net.cpp:131] Top shape: 100 10 31 33 (1023000)\n",
    "I0524 09:37:37.155351  4162 net.cpp:139] Memory required for data: 9336400\n",
    "I0524 09:37:37.155357  4162 layer_factory.hpp:77] Creating layer pool1\n",
    "I0524 09:37:37.155369  4162 net.cpp:86] Creating Layer pool1\n",
    "I0524 09:37:37.155382  4162 net.cpp:408] pool1 <- conv1\n",
    "I0524 09:37:37.155400  4162 net.cpp:382] pool1 -> pool1\n",
    "I0524 09:37:37.155453  4162 net.cpp:124] Setting up pool1\n",
    "I0524 09:37:37.155464  4162 net.cpp:131] Top shape: 100 10 15 16 (240000)\n",
    "I0524 09:37:37.155470  4162 net.cpp:139] Memory required for data: 10296400\n",
    "I0524 09:37:37.155475  4162 layer_factory.hpp:77] Creating layer ip1\n",
    "I0524 09:37:37.155488  4162 net.cpp:86] Creating Layer ip1\n",
    "I0524 09:37:37.155495  4162 net.cpp:408] ip1 <- pool1\n",
    "I0524 09:37:37.155504  4162 net.cpp:382] ip1 -> ip1\n",
    "I0524 09:37:37.156839  4162 net.cpp:124] Setting up ip1\n",
    "I0524 09:37:37.156857  4162 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:37:37.156863  4162 net.cpp:139] Memory required for data: 10304400\n",
    "I0524 09:37:37.156875  4162 layer_factory.hpp:77] Creating layer loss\n",
    "I0524 09:37:37.156888  4162 net.cpp:86] Creating Layer loss\n",
    "I0524 09:37:37.156894  4162 net.cpp:408] loss <- ip1\n",
    "I0524 09:37:37.156903  4162 net.cpp:408] loss <- label\n",
    "I0524 09:37:37.156911  4162 net.cpp:382] loss -> loss\n",
    "I0524 09:37:37.156929  4162 layer_factory.hpp:77] Creating layer loss\n",
    "I0524 09:37:37.157490  4162 net.cpp:124] Setting up loss\n",
    "I0524 09:37:37.157503  4162 net.cpp:131] Top shape: (1)\n",
    "I0524 09:37:37.157510  4162 net.cpp:134]     with loss weight 1\n",
    "I0524 09:37:37.157532  4162 net.cpp:139] Memory required for data: 10304404\n",
    "I0524 09:37:37.157539  4162 net.cpp:200] loss needs backward computation.\n",
    "I0524 09:37:37.157549  4162 net.cpp:200] ip1 needs backward computation.\n",
    "I0524 09:37:37.157557  4162 net.cpp:200] pool1 needs backward computation.\n",
    "I0524 09:37:37.157562  4162 net.cpp:200] relu1 needs backward computation.\n",
    "I0524 09:37:37.157567  4162 net.cpp:200] conv1 needs backward computation.\n",
    "I0524 09:37:37.157574  4162 net.cpp:202] cmu does not need backward computation.\n",
    "I0524 09:37:37.157579  4162 net.cpp:244] This network produces output loss\n",
    "I0524 09:37:37.157593  4162 net.cpp:257] Network initialization done.\n",
    "I0524 09:37:37.157770  4162 solver.cpp:173] Creating test net (#0) specified by net file: example_topology.prototxt\n",
    "I0524 09:37:37.157799  4162 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer cmu\n",
    "I0524 09:37:37.157901  4162 net.cpp:53] Initializing net from parameters: \n",
    "name: \"simpleNet\"\n",
    "state {\n",
    "  phase: TEST\n",
    "}\n",
    "layer {\n",
    "  name: \"cmu\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"cmu-list-test.txt\"\n",
    "    batch_size: 100\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    pad_h: 2\n",
    "    pad_w: 2\n",
    "    kernel_h: 4\n",
    "    kernel_w: 4\n",
    "    stride_h: 1\n",
    "    stride_w: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"conv1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"pool1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 3\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool1\"\n",
    "  top: \"ip1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 20\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"accuracy_1\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"ip1\"\n",
    "  bottom: \"label\"\n",
    "  top: \"accuracy_1\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  accuracy_param {\n",
    "    top_k: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"ip1\"\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "}\n",
    "I0524 09:37:37.157974  4162 layer_factory.hpp:77] Creating layer cmu\n",
    "I0524 09:37:37.157992  4162 net.cpp:86] Creating Layer cmu\n",
    "I0524 09:37:37.158002  4162 net.cpp:382] cmu -> data\n",
    "I0524 09:37:37.158015  4162 net.cpp:382] cmu -> label\n",
    "I0524 09:37:37.158027  4162 image_data_layer.cpp:38] Opening file cmu-list-test.txt\n",
    "I0524 09:37:37.158154  4162 image_data_layer.cpp:63] A total of 184 images.\n",
    "I0524 09:37:37.158285  4162 image_data_layer.cpp:90] output data size: 100,3,30,32\n",
    "I0524 09:37:37.162545  4162 net.cpp:124] Setting up cmu\n",
    "I0524 09:37:37.162582  4162 net.cpp:131] Top shape: 100 3 30 32 (288000)\n",
    "I0524 09:37:37.162591  4162 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:37:37.162596  4162 net.cpp:139] Memory required for data: 1152400\n",
    "I0524 09:37:37.162606  4162 layer_factory.hpp:77] Creating layer label_cmu_1_split\n",
    "I0524 09:37:37.162622  4162 net.cpp:86] Creating Layer label_cmu_1_split\n",
    "I0524 09:37:37.162629  4162 net.cpp:408] label_cmu_1_split <- label\n",
    "I0524 09:37:37.162642  4162 net.cpp:382] label_cmu_1_split -> label_cmu_1_split_0\n",
    "I0524 09:37:37.162657  4162 net.cpp:382] label_cmu_1_split -> label_cmu_1_split_1\n",
    "I0524 09:37:37.162736  4162 net.cpp:124] Setting up label_cmu_1_split\n",
    "I0524 09:37:37.162752  4162 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:37:37.162762  4162 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:37:37.162767  4162 net.cpp:139] Memory required for data: 1153200\n",
    "I0524 09:37:37.162773  4162 layer_factory.hpp:77] Creating layer conv1\n",
    "I0524 09:37:37.162791  4162 net.cpp:86] Creating Layer conv1\n",
    "I0524 09:37:37.162796  4162 net.cpp:408] conv1 <- data\n",
    "I0524 09:37:37.162808  4162 net.cpp:382] conv1 -> conv1\n",
    "I0524 09:37:37.163091  4162 net.cpp:124] Setting up conv1\n",
    "I0524 09:37:37.163105  4162 net.cpp:131] Top shape: 100 10 31 33 (1023000)\n",
    "I0524 09:37:37.163110  4162 net.cpp:139] Memory required for data: 5245200\n",
    "I0524 09:37:37.163125  4162 layer_factory.hpp:77] Creating layer relu1\n",
    "I0524 09:37:37.163136  4162 net.cpp:86] Creating Layer relu1\n",
    "I0524 09:37:37.163142  4162 net.cpp:408] relu1 <- conv1\n",
    "I0524 09:37:37.163151  4162 net.cpp:369] relu1 -> conv1 (in-place)\n",
    "I0524 09:37:37.163161  4162 net.cpp:124] Setting up relu1\n",
    "I0524 09:37:37.163168  4162 net.cpp:131] Top shape: 100 10 31 33 (1023000)\n",
    "I0524 09:37:37.163173  4162 net.cpp:139] Memory required for data: 9337200\n",
    "I0524 09:37:37.163179  4162 layer_factory.hpp:77] Creating layer pool1\n",
    "I0524 09:37:37.163192  4162 net.cpp:86] Creating Layer pool1\n",
    "I0524 09:37:37.163197  4162 net.cpp:408] pool1 <- conv1\n",
    "I0524 09:37:37.163205  4162 net.cpp:382] pool1 -> pool1\n",
    "I0524 09:37:37.163257  4162 net.cpp:124] Setting up pool1\n",
    "I0524 09:37:37.163269  4162 net.cpp:131] Top shape: 100 10 15 16 (240000)\n",
    "I0524 09:37:37.163274  4162 net.cpp:139] Memory required for data: 10297200\n",
    "I0524 09:37:37.163280  4162 layer_factory.hpp:77] Creating layer ip1\n",
    "I0524 09:37:37.163290  4162 net.cpp:86] Creating Layer ip1\n",
    "I0524 09:37:37.163295  4162 net.cpp:408] ip1 <- pool1\n",
    "I0524 09:37:37.163306  4162 net.cpp:382] ip1 -> ip1\n",
    "I0524 09:37:37.164397  4162 net.cpp:124] Setting up ip1\n",
    "I0524 09:37:37.164409  4162 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:37:37.164414  4162 net.cpp:139] Memory required for data: 10305200\n",
    "I0524 09:37:37.164428  4162 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
    "I0524 09:37:37.164438  4162 net.cpp:86] Creating Layer ip1_ip1_0_split\n",
    "I0524 09:37:37.164444  4162 net.cpp:408] ip1_ip1_0_split <- ip1\n",
    "I0524 09:37:37.164453  4162 net.cpp:382] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
    "I0524 09:37:37.164466  4162 net.cpp:382] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
    "I0524 09:37:37.164750  4162 net.cpp:124] Setting up ip1_ip1_0_split\n",
    "I0524 09:37:37.164763  4162 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:37:37.164770  4162 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:37:37.164775  4162 net.cpp:139] Memory required for data: 10321200\n",
    "I0524 09:37:37.164782  4162 layer_factory.hpp:77] Creating layer accuracy_1\n",
    "I0524 09:37:37.164793  4162 net.cpp:86] Creating Layer accuracy_1\n",
    "I0524 09:37:37.164798  4162 net.cpp:408] accuracy_1 <- ip1_ip1_0_split_0\n",
    "I0524 09:37:37.164805  4162 net.cpp:408] accuracy_1 <- label_cmu_1_split_0\n",
    "I0524 09:37:37.164815  4162 net.cpp:382] accuracy_1 -> accuracy_1\n",
    "I0524 09:37:37.164829  4162 net.cpp:124] Setting up accuracy_1\n",
    "I0524 09:37:37.164837  4162 net.cpp:131] Top shape: (1)\n",
    "I0524 09:37:37.164842  4162 net.cpp:139] Memory required for data: 10321204\n",
    "I0524 09:37:37.164857  4162 layer_factory.hpp:77] Creating layer loss\n",
    "I0524 09:37:37.164876  4162 net.cpp:86] Creating Layer loss\n",
    "I0524 09:37:37.164883  4162 net.cpp:408] loss <- ip1_ip1_0_split_1\n",
    "I0524 09:37:37.164891  4162 net.cpp:408] loss <- label_cmu_1_split_1\n",
    "I0524 09:37:37.164898  4162 net.cpp:382] loss -> loss\n",
    "I0524 09:37:37.164911  4162 layer_factory.hpp:77] Creating layer loss\n",
    "I0524 09:37:37.165014  4162 net.cpp:124] Setting up loss\n",
    "I0524 09:37:37.165024  4162 net.cpp:131] Top shape: (1)\n",
    "I0524 09:37:37.165030  4162 net.cpp:134]     with loss weight 1\n",
    "I0524 09:37:37.165045  4162 net.cpp:139] Memory required for data: 10321208\n",
    "I0524 09:37:37.165051  4162 net.cpp:200] loss needs backward computation.\n",
    "I0524 09:37:37.165058  4162 net.cpp:202] accuracy_1 does not need backward computation.\n",
    "I0524 09:37:37.165066  4162 net.cpp:200] ip1_ip1_0_split needs backward computation.\n",
    "I0524 09:37:37.165071  4162 net.cpp:200] ip1 needs backward computation.\n",
    "I0524 09:37:37.165076  4162 net.cpp:200] pool1 needs backward computation.\n",
    "I0524 09:37:37.165082  4162 net.cpp:200] relu1 needs backward computation.\n",
    "I0524 09:37:37.165087  4162 net.cpp:200] conv1 needs backward computation.\n",
    "I0524 09:37:37.165096  4162 net.cpp:202] label_cmu_1_split does not need backward computation.\n",
    "I0524 09:37:37.165102  4162 net.cpp:202] cmu does not need backward computation.\n",
    "I0524 09:37:37.165107  4162 net.cpp:244] This network produces output accuracy_1\n",
    "I0524 09:37:37.165113  4162 net.cpp:244] This network produces output loss\n",
    "I0524 09:37:37.165127  4162 net.cpp:257] Network initialization done.\n",
    "I0524 09:37:37.165164  4162 solver.cpp:56] Solver scaffolding done.\n",
    "I0524 09:37:37.165331  4162 caffe.cpp:248] Starting Optimization\n",
    "I0524 09:37:37.165340  4162 solver.cpp:273] Solving simpleNet\n",
    "I0524 09:37:37.165345  4162 solver.cpp:274] Learning Rate Policy: fixed\n",
    "I0524 09:37:37.165727  4162 solver.cpp:331] Iteration 0, Testing net (#0)\n",
    "I0524 09:37:37.165819  4162 blocking_queue.cpp:49] Waiting for data\n",
    "I0524 09:37:38.454568  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 0.0546\n",
    "I0524 09:37:38.454612  4162 solver.cpp:398]     Test net output #1: loss = 3.16527 (* 1 = 3.16527 loss)\n",
    "I0524 09:37:38.487490  4162 solver.cpp:219] Iteration 0 (0 iter/s, 1.32212s/100 iters), loss = 3.13353\n",
    "I0524 09:37:38.487529  4162 solver.cpp:238]     Train net output #0: loss = 3.13353 (* 1 = 3.13353 loss)\n",
    "I0524 09:37:38.487540  4162 sgd_solver.cpp:105] Iteration 0, lr = 0.001\n",
    "I0524 09:37:41.756943  4162 solver.cpp:219] Iteration 100 (30.5866 iter/s, 3.26941s/100 iters), loss = 2.9128\n",
    "I0524 09:37:41.757009  4162 solver.cpp:238]     Train net output #0: loss = 2.9128 (* 1 = 2.9128 loss)\n",
    "I0524 09:37:41.757019  4162 sgd_solver.cpp:105] Iteration 100, lr = 0.001\n",
    "I0524 09:37:45.030725  4162 solver.cpp:219] Iteration 200 (30.5463 iter/s, 3.27372s/100 iters), loss = 2.84404\n",
    "I0524 09:37:45.030788  4162 solver.cpp:238]     Train net output #0: loss = 2.84404 (* 1 = 2.84404 loss)\n",
    "I0524 09:37:45.030798  4162 sgd_solver.cpp:105] Iteration 200, lr = 0.001\n",
    "I0524 09:37:48.415913  4162 solver.cpp:219] Iteration 300 (29.5409 iter/s, 3.38514s/100 iters), loss = 2.3668\n",
    "I0524 09:37:48.415983  4162 solver.cpp:238]     Train net output #0: loss = 2.3668 (* 1 = 2.3668 loss)\n",
    "I0524 09:37:48.415994  4162 sgd_solver.cpp:105] Iteration 300, lr = 0.001\n",
    "I0524 09:37:51.776244  4162 solver.cpp:219] Iteration 400 (29.7599 iter/s, 3.36022s/100 iters), loss = 1.48982\n",
    "I0524 09:37:51.776304  4162 solver.cpp:238]     Train net output #0: loss = 1.48982 (* 1 = 1.48982 loss)\n",
    "I0524 09:37:51.776312  4162 sgd_solver.cpp:105] Iteration 400, lr = 0.001\n",
    "I0524 09:37:55.080899  4162 solver.cpp:331] Iteration 500, Testing net (#0)\n",
    "I0524 09:37:56.413162  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 0.8424\n",
    "I0524 09:37:56.413213  4162 solver.cpp:398]     Test net output #1: loss = 0.941587 (* 1 = 0.941587 loss)\n",
    "I0524 09:37:56.456413  4162 solver.cpp:219] Iteration 500 (21.367 iter/s, 4.68012s/100 iters), loss = 0.738047\n",
    "I0524 09:37:56.456466  4162 solver.cpp:238]     Train net output #0: loss = 0.738047 (* 1 = 0.738047 loss)\n",
    "I0524 09:37:56.456485  4162 sgd_solver.cpp:105] Iteration 500, lr = 0.001\n",
    "I0524 09:37:59.731493  4162 solver.cpp:219] Iteration 600 (30.5341 iter/s, 3.27503s/100 iters), loss = 0.449464\n",
    "I0524 09:37:59.731557  4162 solver.cpp:238]     Train net output #0: loss = 0.449464 (* 1 = 0.449464 loss)\n",
    "I0524 09:37:59.731567  4162 sgd_solver.cpp:105] Iteration 600, lr = 0.001\n",
    "I0524 09:38:03.142069  4162 solver.cpp:219] Iteration 700 (29.321 iter/s, 3.41052s/100 iters), loss = 0.260835\n",
    "I0524 09:38:03.142134  4162 solver.cpp:238]     Train net output #0: loss = 0.260835 (* 1 = 0.260835 loss)\n",
    "I0524 09:38:03.142144  4162 sgd_solver.cpp:105] Iteration 700, lr = 0.001\n",
    "I0524 09:38:06.660660  4162 solver.cpp:219] Iteration 800 (28.4209 iter/s, 3.51853s/100 iters), loss = 0.136436\n",
    "I0524 09:38:06.660725  4162 solver.cpp:238]     Train net output #0: loss = 0.136436 (* 1 = 0.136436 loss)\n",
    "I0524 09:38:06.660737  4162 sgd_solver.cpp:105] Iteration 800, lr = 0.001\n",
    "I0524 09:38:10.014672  4162 solver.cpp:219] Iteration 900 (29.816 iter/s, 3.35391s/100 iters), loss = 0.110831\n",
    "I0524 09:38:10.014832  4162 solver.cpp:238]     Train net output #0: loss = 0.110831 (* 1 = 0.110831 loss)\n",
    "I0524 09:38:10.014847  4162 sgd_solver.cpp:105] Iteration 900, lr = 0.001\n",
    "I0524 09:38:13.343618  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_1000.caffemodel\n",
    "I0524 09:38:13.363246  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_1000.solverstate\n",
    "I0524 09:38:13.363718  4162 solver.cpp:331] Iteration 1000, Testing net (#0)\n",
    "I0524 09:38:14.701267  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 0.9837\n",
    "I0524 09:38:14.701329  4162 solver.cpp:398]     Test net output #1: loss = 0.128733 (* 1 = 0.128733 loss)\n",
    "I0524 09:38:14.744052  4162 solver.cpp:219] Iteration 1000 (21.1481 iter/s, 4.72856s/100 iters), loss = 0.109017\n",
    "I0524 09:38:14.744114  4162 solver.cpp:238]     Train net output #0: loss = 0.109017 (* 1 = 0.109017 loss)\n",
    "I0524 09:38:14.744129  4162 sgd_solver.cpp:105] Iteration 1000, lr = 0.001\n",
    "I0524 09:38:18.106900  4162 solver.cpp:219] Iteration 1100 (29.7372 iter/s, 3.36279s/100 iters), loss = 0.0641378\n",
    "I0524 09:38:18.106963  4162 solver.cpp:238]     Train net output #0: loss = 0.0641378 (* 1 = 0.0641378 loss)\n",
    "I0524 09:38:18.106978  4162 sgd_solver.cpp:105] Iteration 1100, lr = 0.001\n",
    "I0524 09:38:21.424394  4162 solver.cpp:219] Iteration 1200 (30.1437 iter/s, 3.31744s/100 iters), loss = 0.04331\n",
    "I0524 09:38:21.424461  4162 solver.cpp:238]     Train net output #0: loss = 0.04331 (* 1 = 0.04331 loss)\n",
    "I0524 09:38:21.424484  4162 sgd_solver.cpp:105] Iteration 1200, lr = 0.001\n",
    "I0524 09:38:24.756947  4162 solver.cpp:219] Iteration 1300 (30.0076 iter/s, 3.33249s/100 iters), loss = 0.0580178\n",
    "I0524 09:38:24.757011  4162 solver.cpp:238]     Train net output #0: loss = 0.0580178 (* 1 = 0.0580178 loss)\n",
    "I0524 09:38:24.757022  4162 sgd_solver.cpp:105] Iteration 1300, lr = 0.001\n",
    "I0524 09:38:28.004739  4162 solver.cpp:219] Iteration 1400 (30.7907 iter/s, 3.24773s/100 iters), loss = 0.0630906\n",
    "I0524 09:38:28.004801  4162 solver.cpp:238]     Train net output #0: loss = 0.0630906 (* 1 = 0.0630906 loss)\n",
    "I0524 09:38:28.004812  4162 sgd_solver.cpp:105] Iteration 1400, lr = 0.001\n",
    "I0524 09:38:31.209379  4162 solver.cpp:331] Iteration 1500, Testing net (#0)\n",
    "I0524 09:38:32.533985  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 0.9892\n",
    "I0524 09:38:32.534060  4162 solver.cpp:398]     Test net output #1: loss = 0.0610432 (* 1 = 0.0610432 loss)\n",
    "I0524 09:38:32.574446  4162 solver.cpp:219] Iteration 1500 (21.8835 iter/s, 4.56964s/100 iters), loss = 0.0337206\n",
    "I0524 09:38:32.574537  4162 solver.cpp:238]     Train net output #0: loss = 0.0337206 (* 1 = 0.0337206 loss)\n",
    "I0524 09:38:32.574556  4162 sgd_solver.cpp:105] Iteration 1500, lr = 0.001\n",
    "I0524 09:38:35.832293  4162 solver.cpp:219] Iteration 1600 (30.6959 iter/s, 3.25776s/100 iters), loss = 0.0315706\n",
    "I0524 09:38:35.832362  4162 solver.cpp:238]     Train net output #0: loss = 0.0315706 (* 1 = 0.0315706 loss)\n",
    "I0524 09:38:35.832388  4162 sgd_solver.cpp:105] Iteration 1600, lr = 0.001\n",
    "I0524 09:38:39.081933  4162 solver.cpp:219] Iteration 1700 (30.7733 iter/s, 3.24957s/100 iters), loss = 0.0330155\n",
    "I0524 09:38:39.081998  4162 solver.cpp:238]     Train net output #0: loss = 0.0330155 (* 1 = 0.0330155 loss)\n",
    "I0524 09:38:39.082012  4162 sgd_solver.cpp:105] Iteration 1700, lr = 0.001\n",
    "I0524 09:38:42.340914  4162 solver.cpp:219] Iteration 1800 (30.6851 iter/s, 3.25891s/100 iters), loss = 0.0301954\n",
    "I0524 09:38:42.341120  4162 solver.cpp:238]     Train net output #0: loss = 0.0301954 (* 1 = 0.0301954 loss)\n",
    "I0524 09:38:42.341135  4162 sgd_solver.cpp:105] Iteration 1800, lr = 0.001\n",
    "I0524 09:38:45.588642  4162 solver.cpp:219] Iteration 1900 (30.7927 iter/s, 3.24753s/100 iters), loss = 0.0218927\n",
    "I0524 09:38:45.588717  4162 solver.cpp:238]     Train net output #0: loss = 0.0218927 (* 1 = 0.0218927 loss)\n",
    "I0524 09:38:45.588732  4162 sgd_solver.cpp:105] Iteration 1900, lr = 0.001\n",
    "I0524 09:38:48.836601  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_2000.caffemodel\n",
    "I0524 09:38:48.856341  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_2000.solverstate\n",
    "I0524 09:38:48.857033  4162 solver.cpp:331] Iteration 2000, Testing net (#0)\n",
    "I0524 09:38:50.211292  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 0.9946\n",
    "I0524 09:38:50.211339  4162 solver.cpp:398]     Test net output #1: loss = 0.0416568 (* 1 = 0.0416568 loss)\n",
    "I0524 09:38:50.253628  4162 solver.cpp:219] Iteration 2000 (21.4366 iter/s, 4.66492s/100 iters), loss = 0.0231767\n",
    "I0524 09:38:50.253690  4162 solver.cpp:238]     Train net output #0: loss = 0.0231767 (* 1 = 0.0231767 loss)\n",
    "I0524 09:38:50.253700  4162 sgd_solver.cpp:105] Iteration 2000, lr = 0.001\n",
    "I0524 09:38:53.520843  4162 solver.cpp:219] Iteration 2100 (30.6076 iter/s, 3.26716s/100 iters), loss = 0.0315019\n",
    "I0524 09:38:53.520910  4162 solver.cpp:238]     Train net output #0: loss = 0.0315019 (* 1 = 0.0315019 loss)\n",
    "I0524 09:38:53.520920  4162 sgd_solver.cpp:105] Iteration 2100, lr = 0.001\n",
    "I0524 09:38:56.834336  4162 solver.cpp:219] Iteration 2200 (30.1802 iter/s, 3.31343s/100 iters), loss = 0.0203698\n",
    "I0524 09:38:56.834395  4162 solver.cpp:238]     Train net output #0: loss = 0.0203698 (* 1 = 0.0203698 loss)\n",
    "I0524 09:38:56.834408  4162 sgd_solver.cpp:105] Iteration 2200, lr = 0.001\n",
    "I0524 09:39:00.176097  4162 solver.cpp:219] Iteration 2300 (29.9249 iter/s, 3.3417s/100 iters), loss = 0.0144738\n",
    "I0524 09:39:00.176156  4162 solver.cpp:238]     Train net output #0: loss = 0.0144738 (* 1 = 0.0144738 loss)\n",
    "I0524 09:39:00.176165  4162 sgd_solver.cpp:105] Iteration 2300, lr = 0.001\n",
    "I0524 09:39:03.600739  4162 solver.cpp:219] Iteration 2400 (29.2006 iter/s, 3.42458s/100 iters), loss = 0.0232172\n",
    "I0524 09:39:03.600805  4162 solver.cpp:238]     Train net output #0: loss = 0.0232172 (* 1 = 0.0232172 loss)\n",
    "I0524 09:39:03.600816  4162 sgd_solver.cpp:105] Iteration 2400, lr = 0.001\n",
    "I0524 09:39:07.104810  4162 solver.cpp:331] Iteration 2500, Testing net (#0)\n",
    "I0524 09:39:08.501761  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:39:08.501809  4162 solver.cpp:398]     Test net output #1: loss = 0.0328183 (* 1 = 0.0328183 loss)\n",
    "I0524 09:39:08.544208  4162 solver.cpp:219] Iteration 2500 (20.229 iter/s, 4.94341s/100 iters), loss = 0.0277763\n",
    "I0524 09:39:08.544265  4162 solver.cpp:238]     Train net output #0: loss = 0.0277763 (* 1 = 0.0277763 loss)\n",
    "I0524 09:39:08.544275  4162 sgd_solver.cpp:105] Iteration 2500, lr = 0.001\n",
    "I0524 09:39:11.994112  4162 solver.cpp:219] Iteration 2600 (28.9868 iter/s, 3.44985s/100 iters), loss = 0.0159244\n",
    "I0524 09:39:11.994171  4162 solver.cpp:238]     Train net output #0: loss = 0.0159244 (* 1 = 0.0159244 loss)\n",
    "I0524 09:39:11.994182  4162 sgd_solver.cpp:105] Iteration 2600, lr = 0.001\n",
    "I0524 09:39:15.384233  4162 solver.cpp:219] Iteration 2700 (29.498 iter/s, 3.39006s/100 iters), loss = 0.015352\n",
    "I0524 09:39:15.384500  4162 solver.cpp:238]     Train net output #0: loss = 0.015352 (* 1 = 0.015352 loss)\n",
    "I0524 09:39:15.384522  4162 sgd_solver.cpp:105] Iteration 2700, lr = 0.001\n",
    "I0524 09:39:18.736104  4162 solver.cpp:219] Iteration 2800 (29.8364 iter/s, 3.35161s/100 iters), loss = 0.0178347\n",
    "I0524 09:39:18.736181  4162 solver.cpp:238]     Train net output #0: loss = 0.0178347 (* 1 = 0.0178347 loss)\n",
    "I0524 09:39:18.736193  4162 sgd_solver.cpp:105] Iteration 2800, lr = 0.001\n",
    "I0524 09:39:22.072757  4162 solver.cpp:219] Iteration 2900 (29.9712 iter/s, 3.33654s/100 iters), loss = 0.0164866\n",
    "I0524 09:39:22.072824  4162 solver.cpp:238]     Train net output #0: loss = 0.0164866 (* 1 = 0.0164866 loss)\n",
    "I0524 09:39:22.072835  4162 sgd_solver.cpp:105] Iteration 2900, lr = 0.001\n",
    "I0524 09:39:25.428822  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_3000.caffemodel\n",
    "I0524 09:39:25.448063  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_3000.solverstate\n",
    "I0524 09:39:25.448551  4162 solver.cpp:331] Iteration 3000, Testing net (#0)\n",
    "I0524 09:39:26.750985  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:39:26.751040  4162 solver.cpp:398]     Test net output #1: loss = 0.0278023 (* 1 = 0.0278023 loss)\n",
    "I0524 09:39:26.793427  4162 solver.cpp:219] Iteration 3000 (21.1837 iter/s, 4.72061s/100 iters), loss = 0.0129362\n",
    "I0524 09:39:26.793485  4162 solver.cpp:238]     Train net output #0: loss = 0.0129362 (* 1 = 0.0129362 loss)\n",
    "I0524 09:39:26.793498  4162 sgd_solver.cpp:105] Iteration 3000, lr = 0.001\n",
    "I0524 09:39:30.055316  4162 solver.cpp:219] Iteration 3100 (30.6577 iter/s, 3.26183s/100 iters), loss = 0.0138865\n",
    "I0524 09:39:30.055380  4162 solver.cpp:238]     Train net output #0: loss = 0.0138865 (* 1 = 0.0138865 loss)\n",
    "I0524 09:39:30.055392  4162 sgd_solver.cpp:105] Iteration 3100, lr = 0.001\n",
    "I0524 09:39:33.328155  4162 solver.cpp:219] Iteration 3200 (30.5551 iter/s, 3.27277s/100 iters), loss = 0.0197965\n",
    "I0524 09:39:33.328217  4162 solver.cpp:238]     Train net output #0: loss = 0.0197965 (* 1 = 0.0197965 loss)\n",
    "I0524 09:39:33.328227  4162 sgd_solver.cpp:105] Iteration 3200, lr = 0.001\n",
    "I0524 09:39:36.577468  4162 solver.cpp:219] Iteration 3300 (30.7763 iter/s, 3.24925s/100 iters), loss = 0.0134535\n",
    "I0524 09:39:36.577533  4162 solver.cpp:238]     Train net output #0: loss = 0.0134535 (* 1 = 0.0134535 loss)\n",
    "I0524 09:39:36.577544  4162 sgd_solver.cpp:105] Iteration 3300, lr = 0.001\n",
    "I0524 09:39:39.847707  4162 solver.cpp:219] Iteration 3400 (30.5794 iter/s, 3.27017s/100 iters), loss = 0.0096597\n",
    "I0524 09:39:39.847771  4162 solver.cpp:238]     Train net output #0: loss = 0.0096597 (* 1 = 0.0096597 loss)\n",
    "I0524 09:39:39.847782  4162 sgd_solver.cpp:105] Iteration 3400, lr = 0.001\n",
    "I0524 09:39:43.054298  4162 solver.cpp:331] Iteration 3500, Testing net (#0)\n",
    "I0524 09:39:44.373374  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:39:44.373422  4162 solver.cpp:398]     Test net output #1: loss = 0.024636 (* 1 = 0.024636 loss)\n",
    "I0524 09:39:44.415890  4162 solver.cpp:219] Iteration 3500 (21.8909 iter/s, 4.56812s/100 iters), loss = 0.0158781\n",
    "I0524 09:39:44.415949  4162 solver.cpp:238]     Train net output #0: loss = 0.0158781 (* 1 = 0.0158781 loss)\n",
    "I0524 09:39:44.415959  4162 sgd_solver.cpp:105] Iteration 3500, lr = 0.001\n",
    "I0524 09:39:47.676272  4162 solver.cpp:219] Iteration 3600 (30.6719 iter/s, 3.26032s/100 iters), loss = 0.0189451\n",
    "I0524 09:39:47.676417  4162 solver.cpp:238]     Train net output #0: loss = 0.0189451 (* 1 = 0.0189451 loss)\n",
    "I0524 09:39:47.676429  4162 sgd_solver.cpp:105] Iteration 3600, lr = 0.001\n",
    "I0524 09:39:51.066009  4162 solver.cpp:219] Iteration 3700 (29.5021 iter/s, 3.38959s/100 iters), loss = 0.0115819\n",
    "I0524 09:39:51.066078  4162 solver.cpp:238]     Train net output #0: loss = 0.0115819 (* 1 = 0.0115819 loss)\n",
    "I0524 09:39:51.066090  4162 sgd_solver.cpp:105] Iteration 3700, lr = 0.001\n",
    "I0524 09:39:54.369591  4162 solver.cpp:219] Iteration 3800 (30.2712 iter/s, 3.30348s/100 iters), loss = 0.0111221\n",
    "I0524 09:39:54.369652  4162 solver.cpp:238]     Train net output #0: loss = 0.0111221 (* 1 = 0.0111221 loss)\n",
    "I0524 09:39:54.369663  4162 sgd_solver.cpp:105] Iteration 3800, lr = 0.001\n",
    "I0524 09:39:57.674412  4162 solver.cpp:219] Iteration 3900 (30.2594 iter/s, 3.30476s/100 iters), loss = 0.0133825\n",
    "I0524 09:39:57.674476  4162 solver.cpp:238]     Train net output #0: loss = 0.0133825 (* 1 = 0.0133825 loss)\n",
    "I0524 09:39:57.674489  4162 sgd_solver.cpp:105] Iteration 3900, lr = 0.001\n",
    "I0524 09:40:00.944862  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_4000.caffemodel\n",
    "I0524 09:40:00.964215  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_4000.solverstate\n",
    "I0524 09:40:00.964712  4162 solver.cpp:331] Iteration 4000, Testing net (#0)\n",
    "I0524 09:40:02.267230  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:40:02.267282  4162 solver.cpp:398]     Test net output #1: loss = 0.0226261 (* 1 = 0.0226261 loss)\n",
    "I0524 09:40:02.306905  4162 solver.cpp:219] Iteration 4000 (21.5869 iter/s, 4.63243s/100 iters), loss = 0.0123773\n",
    "I0524 09:40:02.306962  4162 solver.cpp:238]     Train net output #0: loss = 0.0123773 (* 1 = 0.0123773 loss)\n",
    "I0524 09:40:02.306973  4162 sgd_solver.cpp:105] Iteration 4000, lr = 0.001\n",
    "I0524 09:40:05.622180  4162 solver.cpp:219] Iteration 4100 (30.1639 iter/s, 3.31522s/100 iters), loss = 0.0101376\n",
    "I0524 09:40:05.622243  4162 solver.cpp:238]     Train net output #0: loss = 0.0101376 (* 1 = 0.0101376 loss)\n",
    "I0524 09:40:05.622256  4162 sgd_solver.cpp:105] Iteration 4100, lr = 0.001\n",
    "I0524 09:40:08.892827  4162 solver.cpp:219] Iteration 4200 (30.5756 iter/s, 3.27058s/100 iters), loss = 0.0107968\n",
    "I0524 09:40:08.892886  4162 solver.cpp:238]     Train net output #0: loss = 0.0107968 (* 1 = 0.0107968 loss)\n",
    "I0524 09:40:08.892896  4162 sgd_solver.cpp:105] Iteration 4200, lr = 0.001\n",
    "I0524 09:40:12.210785  4162 solver.cpp:219] Iteration 4300 (30.1396 iter/s, 3.3179s/100 iters), loss = 0.0154077\n",
    "I0524 09:40:12.210845  4162 solver.cpp:238]     Train net output #0: loss = 0.0154077 (* 1 = 0.0154077 loss)\n",
    "I0524 09:40:12.210856  4162 sgd_solver.cpp:105] Iteration 4300, lr = 0.001\n",
    "I0524 09:40:15.612520  4162 solver.cpp:219] Iteration 4400 (29.3973 iter/s, 3.40167s/100 iters), loss = 0.010932\n",
    "I0524 09:40:15.612584  4162 solver.cpp:238]     Train net output #0: loss = 0.010932 (* 1 = 0.010932 loss)\n",
    "I0524 09:40:15.612594  4162 sgd_solver.cpp:105] Iteration 4400, lr = 0.001\n",
    "I0524 09:40:18.984045  4162 solver.cpp:331] Iteration 4500, Testing net (#0)\n",
    "I0524 09:40:20.294950  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:40:20.295001  4162 solver.cpp:398]     Test net output #1: loss = 0.0211126 (* 1 = 0.0211126 loss)\n",
    "I0524 09:40:20.337355  4162 solver.cpp:219] Iteration 4500 (21.165 iter/s, 4.72477s/100 iters), loss = 0.00794127\n",
    "I0524 09:40:20.337414  4162 solver.cpp:238]     Train net output #0: loss = 0.00794127 (* 1 = 0.00794127 loss)\n",
    "I0524 09:40:20.337424  4162 sgd_solver.cpp:105] Iteration 4500, lr = 0.001\n",
    "I0524 09:40:23.651091  4162 solver.cpp:219] Iteration 4600 (30.178 iter/s, 3.31367s/100 iters), loss = 0.0129728\n",
    "I0524 09:40:23.651192  4162 solver.cpp:238]     Train net output #0: loss = 0.0129728 (* 1 = 0.0129728 loss)\n",
    "I0524 09:40:23.651211  4162 sgd_solver.cpp:105] Iteration 4600, lr = 0.001\n",
    "I0524 09:40:27.086902  4162 solver.cpp:219] Iteration 4700 (29.1064 iter/s, 3.43568s/100 iters), loss = 0.0152657\n",
    "I0524 09:40:27.086966  4162 solver.cpp:238]     Train net output #0: loss = 0.0152657 (* 1 = 0.0152657 loss)\n",
    "I0524 09:40:27.086978  4162 sgd_solver.cpp:105] Iteration 4700, lr = 0.001\n",
    "I0524 09:40:30.380985  4162 solver.cpp:219] Iteration 4800 (30.3581 iter/s, 3.29402s/100 iters), loss = 0.00983371\n",
    "I0524 09:40:30.381047  4162 solver.cpp:238]     Train net output #0: loss = 0.00983371 (* 1 = 0.00983371 loss)\n",
    "I0524 09:40:30.381059  4162 sgd_solver.cpp:105] Iteration 4800, lr = 0.001\n",
    "I0524 09:40:33.701912  4162 solver.cpp:219] Iteration 4900 (30.1127 iter/s, 3.32086s/100 iters), loss = 0.00938075\n",
    "I0524 09:40:33.701972  4162 solver.cpp:238]     Train net output #0: loss = 0.00938075 (* 1 = 0.00938075 loss)\n",
    "I0524 09:40:33.701982  4162 sgd_solver.cpp:105] Iteration 4900, lr = 0.001\n",
    "I0524 09:40:36.976259  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_5000.caffemodel\n",
    "I0524 09:40:36.998486  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_5000.solverstate\n",
    "I0524 09:40:36.998951  4162 solver.cpp:331] Iteration 5000, Testing net (#0)\n",
    "I0524 09:40:38.325582  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:40:38.325631  4162 solver.cpp:398]     Test net output #1: loss = 0.0200502 (* 1 = 0.0200502 loss)\n",
    "I0524 09:40:38.365285  4162 solver.cpp:219] Iteration 5000 (21.444 iter/s, 4.66331s/100 iters), loss = 0.0114336\n",
    "I0524 09:40:38.365344  4162 solver.cpp:238]     Train net output #0: loss = 0.0114336 (* 1 = 0.0114336 loss)\n",
    "I0524 09:40:38.365355  4162 sgd_solver.cpp:105] Iteration 5000, lr = 0.001\n",
    "I0524 09:40:41.610021  4162 solver.cpp:219] Iteration 5100 (30.8197 iter/s, 3.24467s/100 iters), loss = 0.0105632\n",
    "I0524 09:40:41.610085  4162 solver.cpp:238]     Train net output #0: loss = 0.0105632 (* 1 = 0.0105632 loss)\n",
    "I0524 09:40:41.610095  4162 sgd_solver.cpp:105] Iteration 5100, lr = 0.001\n",
    "I0524 09:40:44.929430  4162 solver.cpp:219] Iteration 5200 (30.1265 iter/s, 3.31934s/100 iters), loss = 0.00891681\n",
    "I0524 09:40:44.929497  4162 solver.cpp:238]     Train net output #0: loss = 0.00891681 (* 1 = 0.00891681 loss)\n",
    "I0524 09:40:44.929507  4162 sgd_solver.cpp:105] Iteration 5200, lr = 0.001\n",
    "I0524 09:40:48.294210  4162 solver.cpp:219] Iteration 5300 (29.7207 iter/s, 3.36466s/100 iters), loss = 0.00939118\n",
    "I0524 09:40:48.294272  4162 solver.cpp:238]     Train net output #0: loss = 0.00939118 (* 1 = 0.00939118 loss)\n",
    "I0524 09:40:48.294283  4162 sgd_solver.cpp:105] Iteration 5300, lr = 0.001\n",
    "I0524 09:40:51.595213  4162 solver.cpp:219] Iteration 5400 (30.2944 iter/s, 3.30094s/100 iters), loss = 0.0132869\n",
    "I0524 09:40:51.595441  4162 solver.cpp:238]     Train net output #0: loss = 0.0132869 (* 1 = 0.0132869 loss)\n",
    "I0524 09:40:51.595454  4162 sgd_solver.cpp:105] Iteration 5400, lr = 0.001\n",
    "I0524 09:40:54.894654  4162 solver.cpp:331] Iteration 5500, Testing net (#0)\n",
    "I0524 09:40:56.208431  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:40:56.208480  4162 solver.cpp:398]     Test net output #1: loss = 0.0191944 (* 1 = 0.0191944 loss)\n",
    "I0524 09:40:56.253286  4162 solver.cpp:219] Iteration 5500 (21.4691 iter/s, 4.65785s/100 iters), loss = 0.0097429\n",
    "I0524 09:40:56.253345  4162 solver.cpp:238]     Train net output #0: loss = 0.0097429 (* 1 = 0.0097429 loss)\n",
    "I0524 09:40:56.253355  4162 sgd_solver.cpp:105] Iteration 5500, lr = 0.001\n",
    "I0524 09:40:59.502538  4162 solver.cpp:219] Iteration 5600 (30.7776 iter/s, 3.24912s/100 iters), loss = 0.0071625\n",
    "I0524 09:40:59.502601  4162 solver.cpp:238]     Train net output #0: loss = 0.0071625 (* 1 = 0.0071625 loss)\n",
    "I0524 09:40:59.502611  4162 sgd_solver.cpp:105] Iteration 5600, lr = 0.001\n",
    "I0524 09:41:02.778125  4162 solver.cpp:219] Iteration 5700 (30.5303 iter/s, 3.27543s/100 iters), loss = 0.0115295\n",
    "I0524 09:41:02.778184  4162 solver.cpp:238]     Train net output #0: loss = 0.0115295 (* 1 = 0.0115295 loss)\n",
    "I0524 09:41:02.778195  4162 sgd_solver.cpp:105] Iteration 5700, lr = 0.001\n",
    "I0524 09:41:06.138818  4162 solver.cpp:219] Iteration 5800 (29.7574 iter/s, 3.36051s/100 iters), loss = 0.0133823\n",
    "I0524 09:41:06.138936  4162 solver.cpp:238]     Train net output #0: loss = 0.0133823 (* 1 = 0.0133823 loss)\n",
    "I0524 09:41:06.138957  4162 sgd_solver.cpp:105] Iteration 5800, lr = 0.001\n",
    "I0524 09:41:09.527958  4162 solver.cpp:219] Iteration 5900 (29.5082 iter/s, 3.38889s/100 iters), loss = 0.00898622\n",
    "I0524 09:41:09.528051  4162 solver.cpp:238]     Train net output #0: loss = 0.00898622 (* 1 = 0.00898622 loss)\n",
    "I0524 09:41:09.528071  4162 sgd_solver.cpp:105] Iteration 5900, lr = 0.001\n",
    "I0524 09:41:12.747975  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_6000.caffemodel\n",
    "I0524 09:41:12.766971  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_6000.solverstate\n",
    "I0524 09:41:12.767570  4162 solver.cpp:331] Iteration 6000, Testing net (#0)\n",
    "I0524 09:41:14.191932  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:41:14.192006  4162 solver.cpp:398]     Test net output #1: loss = 0.018608 (* 1 = 0.018608 loss)\n",
    "I0524 09:41:14.230156  4162 solver.cpp:219] Iteration 6000 (21.2677 iter/s, 4.70197s/100 iters), loss = 0.00851768\n",
    "I0524 09:41:14.230252  4162 solver.cpp:238]     Train net output #0: loss = 0.00851768 (* 1 = 0.00851768 loss)\n",
    "I0524 09:41:14.230273  4162 sgd_solver.cpp:105] Iteration 6000, lr = 0.001\n",
    "I0524 09:41:17.577870  4162 solver.cpp:219] Iteration 6100 (29.8733 iter/s, 3.34747s/100 iters), loss = 0.0104278\n",
    "I0524 09:41:17.577970  4162 solver.cpp:238]     Train net output #0: loss = 0.0104278 (* 1 = 0.0104278 loss)\n",
    "I0524 09:41:17.577989  4162 sgd_solver.cpp:105] Iteration 6100, lr = 0.001\n",
    "I0524 09:41:20.854583  4162 solver.cpp:219] Iteration 6200 (30.5205 iter/s, 3.27649s/100 iters), loss = 0.00961617\n",
    "I0524 09:41:20.854650  4162 solver.cpp:238]     Train net output #0: loss = 0.00961617 (* 1 = 0.00961617 loss)\n",
    "I0524 09:41:20.854662  4162 sgd_solver.cpp:105] Iteration 6200, lr = 0.001\n",
    "I0524 09:41:24.279404  4162 solver.cpp:219] Iteration 6300 (29.2 iter/s, 3.42466s/100 iters), loss = 0.00830724\n",
    "I0524 09:41:24.279667  4162 solver.cpp:238]     Train net output #0: loss = 0.00830724 (* 1 = 0.00830724 loss)\n",
    "I0524 09:41:24.279682  4162 sgd_solver.cpp:105] Iteration 6300, lr = 0.001\n",
    "I0524 09:41:27.673888  4162 solver.cpp:219] Iteration 6400 (29.4632 iter/s, 3.39407s/100 iters), loss = 0.00865309\n",
    "I0524 09:41:27.673974  4162 solver.cpp:238]     Train net output #0: loss = 0.00865309 (* 1 = 0.00865309 loss)\n",
    "I0524 09:41:27.673985  4162 sgd_solver.cpp:105] Iteration 6400, lr = 0.001\n",
    "I0524 09:41:31.032577  4162 solver.cpp:331] Iteration 6500, Testing net (#0)\n",
    "I0524 09:41:32.359585  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:41:32.359634  4162 solver.cpp:398]     Test net output #1: loss = 0.0181578 (* 1 = 0.0181578 loss)\n",
    "I0524 09:41:32.399485  4162 solver.cpp:219] Iteration 6500 (21.1625 iter/s, 4.72534s/100 iters), loss = 0.0121143\n",
    "I0524 09:41:32.399543  4162 solver.cpp:238]     Train net output #0: loss = 0.0121143 (* 1 = 0.0121143 loss)\n",
    "I0524 09:41:32.399554  4162 sgd_solver.cpp:105] Iteration 6500, lr = 0.001\n",
    "I0524 09:41:35.656714  4162 solver.cpp:219] Iteration 6600 (30.7024 iter/s, 3.25708s/100 iters), loss = 0.00911392\n",
    "I0524 09:41:35.656790  4162 solver.cpp:238]     Train net output #0: loss = 0.00911392 (* 1 = 0.00911392 loss)\n",
    "I0524 09:41:35.656801  4162 sgd_solver.cpp:105] Iteration 6600, lr = 0.001\n",
    "I0524 09:41:38.922246  4162 solver.cpp:219] Iteration 6700 (30.6248 iter/s, 3.26533s/100 iters), loss = 0.00677331\n",
    "I0524 09:41:38.922303  4162 solver.cpp:238]     Train net output #0: loss = 0.00677331 (* 1 = 0.00677331 loss)\n",
    "I0524 09:41:38.922314  4162 sgd_solver.cpp:105] Iteration 6700, lr = 0.001\n",
    "I0524 09:41:42.196156  4162 solver.cpp:219] Iteration 6800 (30.5459 iter/s, 3.27376s/100 iters), loss = 0.0107255\n",
    "I0524 09:41:42.196218  4162 solver.cpp:238]     Train net output #0: loss = 0.0107255 (* 1 = 0.0107255 loss)\n",
    "I0524 09:41:42.196228  4162 sgd_solver.cpp:105] Iteration 6800, lr = 0.001\n",
    "I0524 09:41:45.468394  4162 solver.cpp:219] Iteration 6900 (30.5616 iter/s, 3.27208s/100 iters), loss = 0.0123001\n",
    "I0524 09:41:45.468459  4162 solver.cpp:238]     Train net output #0: loss = 0.0123001 (* 1 = 0.0123001 loss)\n",
    "I0524 09:41:45.468469  4162 sgd_solver.cpp:105] Iteration 6900, lr = 0.001\n",
    "I0524 09:41:48.678766  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_7000.caffemodel\n",
    "I0524 09:41:48.700412  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_7000.solverstate\n",
    "I0524 09:41:48.700911  4162 solver.cpp:331] Iteration 7000, Testing net (#0)\n",
    "I0524 09:41:49.988093  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:41:49.988142  4162 solver.cpp:398]     Test net output #1: loss = 0.0176944 (* 1 = 0.0176944 loss)\n",
    "I0524 09:41:50.030369  4162 solver.cpp:219] Iteration 7000 (21.9213 iter/s, 4.56178s/100 iters), loss = 0.00853748\n",
    "I0524 09:41:50.030447  4162 solver.cpp:238]     Train net output #0: loss = 0.00853748 (* 1 = 0.00853748 loss)\n",
    "I0524 09:41:50.030459  4162 sgd_solver.cpp:105] Iteration 7000, lr = 0.001\n",
    "I0524 09:41:53.308239  4162 solver.cpp:219] Iteration 7100 (30.5092 iter/s, 3.2777s/100 iters), loss = 0.00804606\n",
    "I0524 09:41:53.308302  4162 solver.cpp:238]     Train net output #0: loss = 0.00804606 (* 1 = 0.00804606 loss)\n",
    "I0524 09:41:53.308315  4162 sgd_solver.cpp:105] Iteration 7100, lr = 0.001\n",
    "I0524 09:41:56.585029  4162 solver.cpp:219] Iteration 7200 (30.5191 iter/s, 3.27663s/100 iters), loss = 0.00985789\n",
    "I0524 09:41:56.585211  4162 solver.cpp:238]     Train net output #0: loss = 0.00985789 (* 1 = 0.00985789 loss)\n",
    "I0524 09:41:56.585222  4162 sgd_solver.cpp:105] Iteration 7200, lr = 0.001\n",
    "I0524 09:41:59.856387  4162 solver.cpp:219] Iteration 7300 (30.571 iter/s, 3.27108s/100 iters), loss = 0.00907345\n",
    "I0524 09:41:59.856478  4162 solver.cpp:238]     Train net output #0: loss = 0.00907345 (* 1 = 0.00907345 loss)\n",
    "I0524 09:41:59.856498  4162 sgd_solver.cpp:105] Iteration 7300, lr = 0.001\n",
    "I0524 09:42:03.153831  4162 solver.cpp:219] Iteration 7400 (30.3282 iter/s, 3.29726s/100 iters), loss = 0.007982\n",
    "I0524 09:42:03.153908  4162 solver.cpp:238]     Train net output #0: loss = 0.007982 (* 1 = 0.007982 loss)\n",
    "I0524 09:42:03.153921  4162 sgd_solver.cpp:105] Iteration 7400, lr = 0.001\n",
    "I0524 09:42:06.397605  4162 solver.cpp:331] Iteration 7500, Testing net (#0)\n",
    "I0524 09:42:07.725445  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:42:07.725519  4162 solver.cpp:398]     Test net output #1: loss = 0.0174223 (* 1 = 0.0174223 loss)\n",
    "I0524 09:42:07.764976  4162 solver.cpp:219] Iteration 7500 (21.6877 iter/s, 4.6109s/100 iters), loss = 0.0082308\n",
    "I0524 09:42:07.765064  4162 solver.cpp:238]     Train net output #0: loss = 0.0082308 (* 1 = 0.0082308 loss)\n",
    "I0524 09:42:07.765084  4162 sgd_solver.cpp:105] Iteration 7500, lr = 0.001\n",
    "I0524 09:42:11.178181  4162 solver.cpp:219] Iteration 7600 (29.3077 iter/s, 3.41207s/100 iters), loss = 0.0114153\n",
    "I0524 09:42:11.178264  4162 solver.cpp:238]     Train net output #0: loss = 0.0114153 (* 1 = 0.0114153 loss)\n",
    "I0524 09:42:11.178284  4162 sgd_solver.cpp:105] Iteration 7600, lr = 0.001\n",
    "I0524 09:42:14.479655  4162 solver.cpp:219] Iteration 7700 (30.291 iter/s, 3.30131s/100 iters), loss = 0.00875929\n",
    "I0524 09:42:14.479734  4162 solver.cpp:238]     Train net output #0: loss = 0.00875929 (* 1 = 0.00875929 loss)\n",
    "I0524 09:42:14.479759  4162 sgd_solver.cpp:105] Iteration 7700, lr = 0.001\n",
    "I0524 09:42:17.767535  4162 solver.cpp:219] Iteration 7800 (30.4162 iter/s, 3.28772s/100 iters), loss = 0.00656996\n",
    "I0524 09:42:17.767618  4162 solver.cpp:238]     Train net output #0: loss = 0.00656996 (* 1 = 0.00656996 loss)\n",
    "I0524 09:42:17.767642  4162 sgd_solver.cpp:105] Iteration 7800, lr = 0.001\n",
    "I0524 09:42:21.102828  4162 solver.cpp:219] Iteration 7900 (29.9839 iter/s, 3.33513s/100 iters), loss = 0.0102392\n",
    "I0524 09:42:21.102895  4162 solver.cpp:238]     Train net output #0: loss = 0.0102392 (* 1 = 0.0102392 loss)\n",
    "I0524 09:42:21.102908  4162 sgd_solver.cpp:105] Iteration 7900, lr = 0.001\n",
    "I0524 09:42:24.425251  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_8000.caffemodel\n",
    "I0524 09:42:24.444576  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_8000.solverstate\n",
    "I0524 09:42:24.445042  4162 solver.cpp:331] Iteration 8000, Testing net (#0)\n",
    "I0524 09:42:25.768281  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:42:25.768332  4162 solver.cpp:398]     Test net output #1: loss = 0.017201 (* 1 = 0.017201 loss)\n",
    "I0524 09:42:25.807934  4162 solver.cpp:219] Iteration 8000 (21.2544 iter/s, 4.70492s/100 iters), loss = 0.0116287\n",
    "I0524 09:42:25.807982  4162 solver.cpp:238]     Train net output #0: loss = 0.0116287 (* 1 = 0.0116287 loss)\n",
    "I0524 09:42:25.807993  4162 sgd_solver.cpp:105] Iteration 8000, lr = 0.001\n",
    "I0524 09:42:29.235334  4162 solver.cpp:219] Iteration 8100 (29.1778 iter/s, 3.42726s/100 iters), loss = 0.00828907\n",
    "I0524 09:42:29.235594  4162 solver.cpp:238]     Train net output #0: loss = 0.00828907 (* 1 = 0.00828907 loss)\n",
    "I0524 09:42:29.235610  4162 sgd_solver.cpp:105] Iteration 8100, lr = 0.001\n",
    "I0524 09:42:32.512928  4162 solver.cpp:219] Iteration 8200 (30.5134 iter/s, 3.27725s/100 iters), loss = 0.00777141\n",
    "I0524 09:42:32.513001  4162 solver.cpp:238]     Train net output #0: loss = 0.00777141 (* 1 = 0.00777141 loss)\n",
    "I0524 09:42:32.513012  4162 sgd_solver.cpp:105] Iteration 8200, lr = 0.001\n",
    "I0524 09:42:35.886523  4162 solver.cpp:219] Iteration 8300 (29.6434 iter/s, 3.37343s/100 iters), loss = 0.00951346\n",
    "I0524 09:42:35.886615  4162 solver.cpp:238]     Train net output #0: loss = 0.00951346 (* 1 = 0.00951346 loss)\n",
    "I0524 09:42:35.886632  4162 sgd_solver.cpp:105] Iteration 8300, lr = 0.001\n",
    "I0524 09:42:39.266139  4162 solver.cpp:219] Iteration 8400 (29.5907 iter/s, 3.37944s/100 iters), loss = 0.00873862\n",
    "I0524 09:42:39.266206  4162 solver.cpp:238]     Train net output #0: loss = 0.00873862 (* 1 = 0.00873862 loss)\n",
    "I0524 09:42:39.266221  4162 sgd_solver.cpp:105] Iteration 8400, lr = 0.001\n",
    "I0524 09:42:42.636404  4162 solver.cpp:331] Iteration 8500, Testing net (#0)\n",
    "I0524 09:42:43.969971  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:42:43.970022  4162 solver.cpp:398]     Test net output #1: loss = 0.016943 (* 1 = 0.016943 loss)\n",
    "I0524 09:42:44.003726  4162 solver.cpp:219] Iteration 8500 (21.1086 iter/s, 4.7374s/100 iters), loss = 0.00780323\n",
    "I0524 09:42:44.003789  4162 solver.cpp:238]     Train net output #0: loss = 0.00780323 (* 1 = 0.00780323 loss)\n",
    "I0524 09:42:44.003801  4162 sgd_solver.cpp:105] Iteration 8500, lr = 0.001\n",
    "I0524 09:42:47.358587  4162 solver.cpp:219] Iteration 8600 (29.8092 iter/s, 3.35467s/100 iters), loss = 0.00797719\n",
    "I0524 09:42:47.358651  4162 solver.cpp:238]     Train net output #0: loss = 0.00797719 (* 1 = 0.00797719 loss)\n",
    "I0524 09:42:47.358661  4162 sgd_solver.cpp:105] Iteration 8600, lr = 0.001\n",
    "I0524 09:42:50.718031  4162 solver.cpp:219] Iteration 8700 (29.7681 iter/s, 3.3593s/100 iters), loss = 0.0109768\n",
    "I0524 09:42:50.718096  4162 solver.cpp:238]     Train net output #0: loss = 0.0109768 (* 1 = 0.0109768 loss)\n",
    "I0524 09:42:50.718107  4162 sgd_solver.cpp:105] Iteration 8700, lr = 0.001\n",
    "I0524 09:42:54.019199  4162 solver.cpp:219] Iteration 8800 (30.2936 iter/s, 3.30103s/100 iters), loss = 0.00855165\n",
    "I0524 09:42:54.019273  4162 solver.cpp:238]     Train net output #0: loss = 0.00855165 (* 1 = 0.00855165 loss)\n",
    "I0524 09:42:54.019284  4162 sgd_solver.cpp:105] Iteration 8800, lr = 0.001\n",
    "I0524 09:42:57.332564  4162 solver.cpp:219] Iteration 8900 (30.1822 iter/s, 3.31321s/100 iters), loss = 0.00646388\n",
    "I0524 09:42:57.332633  4162 solver.cpp:238]     Train net output #0: loss = 0.00646388 (* 1 = 0.00646388 loss)\n",
    "I0524 09:42:57.332643  4162 sgd_solver.cpp:105] Iteration 8900, lr = 0.001\n",
    "I0524 09:43:00.561705  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_9000.caffemodel\n",
    "I0524 09:43:00.583497  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_9000.solverstate\n",
    "I0524 09:43:00.583958  4162 solver.cpp:331] Iteration 9000, Testing net (#0)\n",
    "I0524 09:43:01.895515  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:43:01.895562  4162 solver.cpp:398]     Test net output #1: loss = 0.0167899 (* 1 = 0.0167899 loss)\n",
    "I0524 09:43:01.935317  4162 solver.cpp:219] Iteration 9000 (21.727 iter/s, 4.60257s/100 iters), loss = 0.00993385\n",
    "I0524 09:43:01.935372  4162 solver.cpp:238]     Train net output #0: loss = 0.00993385 (* 1 = 0.00993385 loss)\n",
    "I0524 09:43:01.935384  4162 sgd_solver.cpp:105] Iteration 9000, lr = 0.001\n",
    "I0524 09:43:05.302301  4162 solver.cpp:219] Iteration 9100 (29.7014 iter/s, 3.36684s/100 iters), loss = 0.0111938\n",
    "I0524 09:43:05.302366  4162 solver.cpp:238]     Train net output #0: loss = 0.0111938 (* 1 = 0.0111938 loss)\n",
    "I0524 09:43:05.302376  4162 sgd_solver.cpp:105] Iteration 9100, lr = 0.001\n",
    "I0524 09:43:08.656893  4162 solver.cpp:219] Iteration 9200 (29.8112 iter/s, 3.35445s/100 iters), loss = 0.00814589\n",
    "I0524 09:43:08.656976  4162 solver.cpp:238]     Train net output #0: loss = 0.00814589 (* 1 = 0.00814589 loss)\n",
    "I0524 09:43:08.656990  4162 sgd_solver.cpp:105] Iteration 9200, lr = 0.001\n",
    "I0524 09:43:12.040331  4162 solver.cpp:219] Iteration 9300 (29.5576 iter/s, 3.38322s/100 iters), loss = 0.00760652\n",
    "I0524 09:43:12.040395  4162 solver.cpp:238]     Train net output #0: loss = 0.00760652 (* 1 = 0.00760652 loss)\n",
    "I0524 09:43:12.040407  4162 sgd_solver.cpp:105] Iteration 9300, lr = 0.001\n",
    "I0524 09:43:15.369006  4162 solver.cpp:219] Iteration 9400 (30.0433 iter/s, 3.32853s/100 iters), loss = 0.00929569\n",
    "I0524 09:43:15.369071  4162 solver.cpp:238]     Train net output #0: loss = 0.00929569 (* 1 = 0.00929569 loss)\n",
    "I0524 09:43:15.369083  4162 sgd_solver.cpp:105] Iteration 9400, lr = 0.001\n",
    "I0524 09:43:18.587818  4162 solver.cpp:331] Iteration 9500, Testing net (#0)\n",
    "I0524 09:43:19.920675  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:43:19.920745  4162 solver.cpp:398]     Test net output #1: loss = 0.0166768 (* 1 = 0.0166768 loss)\n",
    "I0524 09:43:19.959870  4162 solver.cpp:219] Iteration 9500 (21.7833 iter/s, 4.59068s/100 iters), loss = 0.00852516\n",
    "I0524 09:43:19.959961  4162 solver.cpp:238]     Train net output #0: loss = 0.00852516 (* 1 = 0.00852516 loss)\n",
    "I0524 09:43:19.959980  4162 sgd_solver.cpp:105] Iteration 9500, lr = 0.001\n",
    "I0524 09:43:23.245872  4162 solver.cpp:219] Iteration 9600 (30.4426 iter/s, 3.28488s/100 iters), loss = 0.00770194\n",
    "I0524 09:43:23.245978  4162 solver.cpp:238]     Train net output #0: loss = 0.00770194 (* 1 = 0.00770194 loss)\n",
    "I0524 09:43:23.245998  4162 sgd_solver.cpp:105] Iteration 9600, lr = 0.001\n",
    "I0524 09:43:26.538003  4162 solver.cpp:219] Iteration 9700 (30.3777 iter/s, 3.29189s/100 iters), loss = 0.00782004\n",
    "I0524 09:43:26.538096  4162 solver.cpp:238]     Train net output #0: loss = 0.00782004 (* 1 = 0.00782004 loss)\n",
    "I0524 09:43:26.538116  4162 sgd_solver.cpp:105] Iteration 9700, lr = 0.001\n",
    "I0524 09:43:29.822160  4162 solver.cpp:219] Iteration 9800 (30.4509 iter/s, 3.28398s/100 iters), loss = 0.010688\n",
    "I0524 09:43:29.822262  4162 solver.cpp:238]     Train net output #0: loss = 0.010688 (* 1 = 0.010688 loss)\n",
    "I0524 09:43:29.822281  4162 sgd_solver.cpp:105] Iteration 9800, lr = 0.001\n",
    "I0524 09:43:33.165843  4162 solver.cpp:219] Iteration 9900 (29.9088 iter/s, 3.34349s/100 iters), loss = 0.00842639\n",
    "I0524 09:43:33.166069  4162 solver.cpp:238]     Train net output #0: loss = 0.00842639 (* 1 = 0.00842639 loss)\n",
    "I0524 09:43:33.166095  4162 sgd_solver.cpp:105] Iteration 9900, lr = 0.001\n",
    "I0524 09:43:36.555197  4162 solver.cpp:448] Snapshotting to binary proto file models/cmu_example_train_iter_10000.caffemodel\n",
    "I0524 09:43:36.576092  4162 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/cmu_example_train_iter_10000.solverstate\n",
    "I0524 09:43:36.599345  4162 solver.cpp:311] Iteration 10000, loss = 0.00640891\n",
    "I0524 09:43:36.599400  4162 solver.cpp:331] Iteration 10000, Testing net (#0)\n",
    "I0524 09:43:37.961864  4162 solver.cpp:398]     Test net output #0: accuracy_1 = 1\n",
    "I0524 09:43:37.961935  4162 solver.cpp:398]     Test net output #1: loss = 0.0165146 (* 1 = 0.0165146 loss)\n",
    "I0524 09:43:37.961953  4162 solver.cpp:316] Optimization Done.\n",
    "I0524 09:43:37.961963  4162 caffe.cpp:259] Optimization Done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained models will be saved in folder 'models'. They permit to execute just a test in CNN, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "./caffe-master/build/tools/caffe test -model example_topology.prototxt -weights models/cmu_example_train_iter_10000.caffemodel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I0524 09:50:13.012673  4374 caffe.cpp:284] Use CPU.\n",
    "I0524 09:50:13.175055  4374 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer cmu\n",
    "I0524 09:50:13.175207  4374 net.cpp:53] Initializing net from parameters: \n",
    "name: \"simpleNet\"\n",
    "state {\n",
    "  phase: TEST\n",
    "  level: 0\n",
    "  stage: \"\"\n",
    "}\n",
    "layer {\n",
    "  name: \"cmu\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"cmu-list-test.txt\"\n",
    "    batch_size: 100\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    pad_h: 2\n",
    "    pad_w: 2\n",
    "    kernel_h: 4\n",
    "    kernel_w: 4\n",
    "    stride_h: 1\n",
    "    stride_w: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"conv1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"pool1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 3\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool1\"\n",
    "  top: \"ip1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 20\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"gaussian\"\n",
    "      mean: 0\n",
    "      std: 0.1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"accuracy_1\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"ip1\"\n",
    "  bottom: \"label\"\n",
    "  top: \"accuracy_1\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  accuracy_param {\n",
    "    top_k: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"ip1\"\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "}\n",
    "I0524 09:50:13.175307  4374 layer_factory.hpp:77] Creating layer cmu\n",
    "I0524 09:50:13.175345  4374 net.cpp:86] Creating Layer cmu\n",
    "I0524 09:50:13.175357  4374 net.cpp:382] cmu -> data\n",
    "I0524 09:50:13.175385  4374 net.cpp:382] cmu -> label\n",
    "I0524 09:50:13.175405  4374 image_data_layer.cpp:38] Opening file cmu-list-test.txt\n",
    "I0524 09:50:13.175536  4374 image_data_layer.cpp:63] A total of 184 images.\n",
    "I0524 09:50:13.175652  4374 image_data_layer.cpp:90] output data size: 100,3,30,32\n",
    "I0524 09:50:13.178158  4374 net.cpp:124] Setting up cmu\n",
    "I0524 09:50:13.178196  4374 net.cpp:131] Top shape: 100 3 30 32 (288000)\n",
    "I0524 09:50:13.178205  4374 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:50:13.178211  4374 net.cpp:139] Memory required for data: 1152400\n",
    "I0524 09:50:13.178221  4374 layer_factory.hpp:77] Creating layer label_cmu_1_split\n",
    "I0524 09:50:13.178237  4374 net.cpp:86] Creating Layer label_cmu_1_split\n",
    "I0524 09:50:13.178246  4374 net.cpp:408] label_cmu_1_split <- label\n",
    "I0524 09:50:13.178264  4374 net.cpp:382] label_cmu_1_split -> label_cmu_1_split_0\n",
    "I0524 09:50:13.178280  4374 net.cpp:382] label_cmu_1_split -> label_cmu_1_split_1\n",
    "I0524 09:50:13.178295  4374 net.cpp:124] Setting up label_cmu_1_split\n",
    "I0524 09:50:13.178304  4374 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:50:13.178313  4374 net.cpp:131] Top shape: 100 (100)\n",
    "I0524 09:50:13.178318  4374 net.cpp:139] Memory required for data: 1153200\n",
    "I0524 09:50:13.178323  4374 layer_factory.hpp:77] Creating layer conv1\n",
    "I0524 09:50:13.178344  4374 net.cpp:86] Creating Layer conv1\n",
    "I0524 09:50:13.178350  4374 net.cpp:408] conv1 <- data\n",
    "I0524 09:50:13.178360  4374 net.cpp:382] conv1 -> conv1\n",
    "I0524 09:50:13.178423  4374 net.cpp:124] Setting up conv1\n",
    "I0524 09:50:13.178436  4374 net.cpp:131] Top shape: 100 10 31 33 (1023000)\n",
    "I0524 09:50:13.178442  4374 net.cpp:139] Memory required for data: 5245200\n",
    "I0524 09:50:13.178468  4374 layer_factory.hpp:77] Creating layer relu1\n",
    "I0524 09:50:13.178478  4374 net.cpp:86] Creating Layer relu1\n",
    "I0524 09:50:13.178484  4374 net.cpp:408] relu1 <- conv1\n",
    "I0524 09:50:13.178494  4374 net.cpp:369] relu1 -> conv1 (in-place)\n",
    "I0524 09:50:13.178504  4374 net.cpp:124] Setting up relu1\n",
    "I0524 09:50:13.178513  4374 net.cpp:131] Top shape: 100 10 31 33 (1023000)\n",
    "I0524 09:50:13.178519  4374 net.cpp:139] Memory required for data: 9337200\n",
    "I0524 09:50:13.178534  4374 layer_factory.hpp:77] Creating layer pool1\n",
    "I0524 09:50:13.178555  4374 net.cpp:86] Creating Layer pool1\n",
    "I0524 09:50:13.178561  4374 net.cpp:408] pool1 <- conv1\n",
    "I0524 09:50:13.178570  4374 net.cpp:382] pool1 -> pool1\n",
    "I0524 09:50:13.178589  4374 net.cpp:124] Setting up pool1\n",
    "I0524 09:50:13.178599  4374 net.cpp:131] Top shape: 100 10 15 16 (240000)\n",
    "I0524 09:50:13.178604  4374 net.cpp:139] Memory required for data: 10297200\n",
    "I0524 09:50:13.178611  4374 layer_factory.hpp:77] Creating layer ip1\n",
    "I0524 09:50:13.178623  4374 net.cpp:86] Creating Layer ip1\n",
    "I0524 09:50:13.178629  4374 net.cpp:408] ip1 <- pool1\n",
    "I0524 09:50:13.178640  4374 net.cpp:382] ip1 -> ip1\n",
    "I0524 09:50:13.179488  4374 net.cpp:124] Setting up ip1\n",
    "I0524 09:50:13.179500  4374 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:50:13.179505  4374 net.cpp:139] Memory required for data: 10305200\n",
    "I0524 09:50:13.179517  4374 layer_factory.hpp:77] Creating layer ip1_ip1_0_split\n",
    "I0524 09:50:13.179530  4374 net.cpp:86] Creating Layer ip1_ip1_0_split\n",
    "I0524 09:50:13.179538  4374 net.cpp:408] ip1_ip1_0_split <- ip1\n",
    "I0524 09:50:13.179546  4374 net.cpp:382] ip1_ip1_0_split -> ip1_ip1_0_split_0\n",
    "I0524 09:50:13.179558  4374 net.cpp:382] ip1_ip1_0_split -> ip1_ip1_0_split_1\n",
    "I0524 09:50:13.179572  4374 net.cpp:124] Setting up ip1_ip1_0_split\n",
    "I0524 09:50:13.179580  4374 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:50:13.179587  4374 net.cpp:131] Top shape: 100 20 (2000)\n",
    "I0524 09:50:13.179592  4374 net.cpp:139] Memory required for data: 10321200\n",
    "I0524 09:50:13.179599  4374 layer_factory.hpp:77] Creating layer accuracy_1\n",
    "I0524 09:50:13.179610  4374 net.cpp:86] Creating Layer accuracy_1\n",
    "I0524 09:50:13.179615  4374 net.cpp:408] accuracy_1 <- ip1_ip1_0_split_0\n",
    "I0524 09:50:13.179622  4374 net.cpp:408] accuracy_1 <- label_cmu_1_split_0\n",
    "I0524 09:50:13.179633  4374 net.cpp:382] accuracy_1 -> accuracy_1\n",
    "I0524 09:50:13.179647  4374 net.cpp:124] Setting up accuracy_1\n",
    "I0524 09:50:13.179656  4374 net.cpp:131] Top shape: (1)\n",
    "I0524 09:50:13.179661  4374 net.cpp:139] Memory required for data: 10321204\n",
    "I0524 09:50:13.179666  4374 layer_factory.hpp:77] Creating layer loss\n",
    "I0524 09:50:13.179678  4374 net.cpp:86] Creating Layer loss\n",
    "I0524 09:50:13.179685  4374 net.cpp:408] loss <- ip1_ip1_0_split_1\n",
    "I0524 09:50:13.179692  4374 net.cpp:408] loss <- label_cmu_1_split_1\n",
    "I0524 09:50:13.179702  4374 net.cpp:382] loss -> loss\n",
    "I0524 09:50:13.179718  4374 layer_factory.hpp:77] Creating layer loss\n",
    "I0524 09:50:13.179744  4374 net.cpp:124] Setting up loss\n",
    "I0524 09:50:13.179752  4374 net.cpp:131] Top shape: (1)\n",
    "I0524 09:50:13.179757  4374 net.cpp:134]     with loss weight 1\n",
    "I0524 09:50:13.179780  4374 net.cpp:139] Memory required for data: 10321208\n",
    "I0524 09:50:13.179785  4374 net.cpp:200] loss needs backward computation.\n",
    "I0524 09:50:13.179795  4374 net.cpp:202] accuracy_1 does not need backward computation.\n",
    "I0524 09:50:13.179802  4374 net.cpp:200] ip1_ip1_0_split needs backward computation.\n",
    "I0524 09:50:13.179808  4374 net.cpp:200] ip1 needs backward computation.\n",
    "I0524 09:50:13.179814  4374 net.cpp:200] pool1 needs backward computation.\n",
    "I0524 09:50:13.179821  4374 net.cpp:200] relu1 needs backward computation.\n",
    "I0524 09:50:13.179826  4374 net.cpp:200] conv1 needs backward computation.\n",
    "I0524 09:50:13.179832  4374 net.cpp:202] label_cmu_1_split does not need backward computation.\n",
    "I0524 09:50:13.179839  4374 net.cpp:202] cmu does not need backward computation.\n",
    "I0524 09:50:13.179844  4374 net.cpp:244] This network produces output accuracy_1\n",
    "I0524 09:50:13.179850  4374 net.cpp:244] This network produces output loss\n",
    "I0524 09:50:13.179868  4374 net.cpp:257] Network initialization done.\n",
    "I0524 09:50:13.180196  4374 caffe.cpp:290] Running for 50 iterations.\n",
    "I0524 09:50:13.180212  4374 blocking_queue.cpp:49] Waiting for data\n",
    "I0524 09:50:13.330309  4374 caffe.cpp:313] Batch 0, accuracy_1 = 1\n",
    "I0524 09:50:13.330399  4374 caffe.cpp:313] Batch 0, loss = 0.0151958\n",
    "I0524 09:50:13.405860  4374 caffe.cpp:313] Batch 1, accuracy_1 = 1\n",
    "I0524 09:50:13.405936  4374 caffe.cpp:313] Batch 1, loss = 0.0169454\n",
    "I0524 09:50:13.449303  4374 caffe.cpp:313] Batch 2, accuracy_1 = 1\n",
    "I0524 09:50:13.449371  4374 caffe.cpp:313] Batch 2, loss = 0.0149213\n",
    "I0524 09:50:13.482587  4374 caffe.cpp:313] Batch 3, accuracy_1 = 1\n",
    "I0524 09:50:13.482630  4374 caffe.cpp:313] Batch 3, loss = 0.0174368\n",
    "I0524 09:50:13.512223  4374 caffe.cpp:313] Batch 4, accuracy_1 = 1\n",
    "I0524 09:50:13.512264  4374 caffe.cpp:313] Batch 4, loss = 0.0142685\n",
    "I0524 09:50:13.539575  4374 caffe.cpp:313] Batch 5, accuracy_1 = 1\n",
    "I0524 09:50:13.539614  4374 caffe.cpp:313] Batch 5, loss = 0.0195001\n",
    "I0524 09:50:13.566206  4374 caffe.cpp:313] Batch 6, accuracy_1 = 1\n",
    "I0524 09:50:13.566242  4374 caffe.cpp:313] Batch 6, loss = 0.0124819\n",
    "I0524 09:50:13.591832  4374 caffe.cpp:313] Batch 7, accuracy_1 = 1\n",
    "I0524 09:50:13.591869  4374 caffe.cpp:313] Batch 7, loss = 0.0207146\n",
    "I0524 09:50:13.617341  4374 caffe.cpp:313] Batch 8, accuracy_1 = 1\n",
    "I0524 09:50:13.617377  4374 caffe.cpp:313] Batch 8, loss = 0.018242\n",
    "I0524 09:50:13.642415  4374 caffe.cpp:313] Batch 9, accuracy_1 = 1\n",
    "I0524 09:50:13.642452  4374 caffe.cpp:313] Batch 9, loss = 0.014821\n",
    "I0524 09:50:13.667505  4374 caffe.cpp:313] Batch 10, accuracy_1 = 1\n",
    "I0524 09:50:13.667541  4374 caffe.cpp:313] Batch 10, loss = 0.0175315\n",
    "I0524 09:50:13.692342  4374 caffe.cpp:313] Batch 11, accuracy_1 = 1\n",
    "I0524 09:50:13.692378  4374 caffe.cpp:313] Batch 11, loss = 0.0152058\n",
    "I0524 09:50:13.717367  4374 caffe.cpp:313] Batch 12, accuracy_1 = 1\n",
    "I0524 09:50:13.717403  4374 caffe.cpp:313] Batch 12, loss = 0.0166631\n",
    "I0524 09:50:13.742424  4374 caffe.cpp:313] Batch 13, accuracy_1 = 1\n",
    "I0524 09:50:13.742460  4374 caffe.cpp:313] Batch 13, loss = 0.0152856\n",
    "I0524 09:50:13.767464  4374 caffe.cpp:313] Batch 14, accuracy_1 = 1\n",
    "I0524 09:50:13.767498  4374 caffe.cpp:313] Batch 14, loss = 0.0173736\n",
    "I0524 09:50:13.792471  4374 caffe.cpp:313] Batch 15, accuracy_1 = 1\n",
    "I0524 09:50:13.792506  4374 caffe.cpp:313] Batch 15, loss = 0.0141563\n",
    "I0524 09:50:13.817442  4374 caffe.cpp:313] Batch 16, accuracy_1 = 1\n",
    "I0524 09:50:13.817478  4374 caffe.cpp:313] Batch 16, loss = 0.0193526\n",
    "I0524 09:50:13.842483  4374 caffe.cpp:313] Batch 17, accuracy_1 = 1\n",
    "I0524 09:50:13.842517  4374 caffe.cpp:313] Batch 17, loss = 0.0127524\n",
    "I0524 09:50:13.867462  4374 caffe.cpp:313] Batch 18, accuracy_1 = 1\n",
    "I0524 09:50:13.867498  4374 caffe.cpp:313] Batch 18, loss = 0.0208004\n",
    "I0524 09:50:13.892525  4374 caffe.cpp:313] Batch 19, accuracy_1 = 1\n",
    "I0524 09:50:13.892560  4374 caffe.cpp:313] Batch 19, loss = 0.0182229\n",
    "I0524 09:50:13.917428  4374 caffe.cpp:313] Batch 20, accuracy_1 = 1\n",
    "I0524 09:50:13.917464  4374 caffe.cpp:313] Batch 20, loss = 0.0145308\n",
    "I0524 09:50:13.942312  4374 caffe.cpp:313] Batch 21, accuracy_1 = 1\n",
    "I0524 09:50:13.942348  4374 caffe.cpp:313] Batch 21, loss = 0.0173672\n",
    "I0524 09:50:13.967382  4374 caffe.cpp:313] Batch 22, accuracy_1 = 1\n",
    "I0524 09:50:13.967419  4374 caffe.cpp:313] Batch 22, loss = 0.0153635\n",
    "I0524 09:50:13.992678  4374 caffe.cpp:313] Batch 23, accuracy_1 = 1\n",
    "I0524 09:50:13.992717  4374 caffe.cpp:313] Batch 23, loss = 0.0169138\n",
    "I0524 09:50:14.019114  4374 caffe.cpp:313] Batch 24, accuracy_1 = 1\n",
    "I0524 09:50:14.019152  4374 caffe.cpp:313] Batch 24, loss = 0.0145977\n",
    "I0524 09:50:14.044204  4374 caffe.cpp:313] Batch 25, accuracy_1 = 1\n",
    "I0524 09:50:14.044242  4374 caffe.cpp:313] Batch 25, loss = 0.0179358\n",
    "I0524 09:50:14.069211  4374 caffe.cpp:313] Batch 26, accuracy_1 = 1\n",
    "I0524 09:50:14.069247  4374 caffe.cpp:313] Batch 26, loss = 0.0141212\n",
    "I0524 09:50:14.094063  4374 caffe.cpp:313] Batch 27, accuracy_1 = 1\n",
    "I0524 09:50:14.094099  4374 caffe.cpp:313] Batch 27, loss = 0.0184973\n",
    "I0524 09:50:14.119109  4374 caffe.cpp:313] Batch 28, accuracy_1 = 1\n",
    "I0524 09:50:14.119144  4374 caffe.cpp:313] Batch 28, loss = 0.0135011\n",
    "I0524 09:50:14.144150  4374 caffe.cpp:313] Batch 29, accuracy_1 = 1\n",
    "I0524 09:50:14.144186  4374 caffe.cpp:313] Batch 29, loss = 0.0208418\n",
    "I0524 09:50:14.169139  4374 caffe.cpp:313] Batch 30, accuracy_1 = 1\n",
    "I0524 09:50:14.169174  4374 caffe.cpp:313] Batch 30, loss = 0.0185309\n",
    "I0524 09:50:14.194062  4374 caffe.cpp:313] Batch 31, accuracy_1 = 1\n",
    "I0524 09:50:14.194097  4374 caffe.cpp:313] Batch 31, loss = 0.0131209\n",
    "I0524 09:50:14.219197  4374 caffe.cpp:313] Batch 32, accuracy_1 = 1\n",
    "I0524 09:50:14.219250  4374 caffe.cpp:313] Batch 32, loss = 0.0184619\n",
    "I0524 09:50:14.244225  4374 caffe.cpp:313] Batch 33, accuracy_1 = 1\n",
    "I0524 09:50:14.244262  4374 caffe.cpp:313] Batch 33, loss = 0.015517\n",
    "I0524 09:50:14.269139  4374 caffe.cpp:313] Batch 34, accuracy_1 = 1\n",
    "I0524 09:50:14.269176  4374 caffe.cpp:313] Batch 34, loss = 0.0167145\n",
    "I0524 09:50:14.295845  4374 caffe.cpp:313] Batch 35, accuracy_1 = 1\n",
    "I0524 09:50:14.295887  4374 caffe.cpp:313] Batch 35, loss = 0.0150434\n",
    "I0524 09:50:14.321983  4374 caffe.cpp:313] Batch 36, accuracy_1 = 1\n",
    "I0524 09:50:14.322024  4374 caffe.cpp:313] Batch 36, loss = 0.0173308\n",
    "I0524 09:50:14.347734  4374 caffe.cpp:313] Batch 37, accuracy_1 = 1\n",
    "I0524 09:50:14.347774  4374 caffe.cpp:313] Batch 37, loss = 0.0145985\n",
    "I0524 09:50:14.373778  4374 caffe.cpp:313] Batch 38, accuracy_1 = 1\n",
    "I0524 09:50:14.373821  4374 caffe.cpp:313] Batch 38, loss = 0.0183722\n",
    "I0524 09:50:14.398955  4374 caffe.cpp:313] Batch 39, accuracy_1 = 1\n",
    "I0524 09:50:14.398991  4374 caffe.cpp:313] Batch 39, loss = 0.0133831\n",
    "I0524 09:50:14.424052  4374 caffe.cpp:313] Batch 40, accuracy_1 = 1\n",
    "I0524 09:50:14.424090  4374 caffe.cpp:313] Batch 40, loss = 0.0195024\n",
    "I0524 09:50:14.449208  4374 caffe.cpp:313] Batch 41, accuracy_1 = 1\n",
    "I0524 09:50:14.449244  4374 caffe.cpp:313] Batch 41, loss = 0.0195848\n",
    "I0524 09:50:14.474228  4374 caffe.cpp:313] Batch 42, accuracy_1 = 1\n",
    "I0524 09:50:14.474267  4374 caffe.cpp:313] Batch 42, loss = 0.0136919\n",
    "I0524 09:50:14.499202  4374 caffe.cpp:313] Batch 43, accuracy_1 = 1\n",
    "I0524 09:50:14.499238  4374 caffe.cpp:313] Batch 43, loss = 0.0180458\n",
    "I0524 09:50:14.524209  4374 caffe.cpp:313] Batch 44, accuracy_1 = 1\n",
    "I0524 09:50:14.524246  4374 caffe.cpp:313] Batch 44, loss = 0.0152498\n",
    "I0524 09:50:14.550493  4374 caffe.cpp:313] Batch 45, accuracy_1 = 1\n",
    "I0524 09:50:14.550532  4374 caffe.cpp:313] Batch 45, loss = 0.0171515\n",
    "I0524 09:50:14.576161  4374 caffe.cpp:313] Batch 46, accuracy_1 = 1\n",
    "I0524 09:50:14.576202  4374 caffe.cpp:313] Batch 46, loss = 0.0151958\n",
    "I0524 09:50:14.601233  4374 caffe.cpp:313] Batch 47, accuracy_1 = 1\n",
    "I0524 09:50:14.601270  4374 caffe.cpp:313] Batch 47, loss = 0.0169454\n",
    "I0524 09:50:14.626190  4374 caffe.cpp:313] Batch 48, accuracy_1 = 1\n",
    "I0524 09:50:14.626226  4374 caffe.cpp:313] Batch 48, loss = 0.0149213\n",
    "I0524 09:50:14.651890  4374 caffe.cpp:313] Batch 49, accuracy_1 = 1\n",
    "I0524 09:50:14.651931  4374 caffe.cpp:313] Batch 49, loss = 0.0174368\n",
    "I0524 09:50:14.651937  4374 caffe.cpp:318] Loss: 0.0164868\n",
    "I0524 09:50:14.651952  4374 caffe.cpp:330] accuracy_1 = 1\n",
    "I0524 09:50:14.651965  4374 caffe.cpp:330] loss = 0.0164868 (* 1 = 0.0164868 loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
